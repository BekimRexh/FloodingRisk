{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e23543a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d6edee",
   "metadata": {},
   "source": [
    "# IDEA\n",
    "- rolling window prediction\n",
    "- create some interactive thing per state\n",
    "- rainfall happened one day, like a lot, likelihood of flood happening, in next few days\n",
    "- rainfall happened over a period of days, likelihood of flood happening\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "79bf246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood = pd.read_csv('../data/Flood Events/floodDataProcessed.csv')\n",
    "df_rainfall = pd.read_csv('../data/Weather Data/daily-rainfall-at-state-level.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c5a8a0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 6)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysis dates will be from 2009 to 2019\n",
    "\n",
    "df_flood[\"year\"] = df_flood[\"Start Date\"].str.extract(r\"(\\d{4})\")\n",
    "df_flood[\"year\"] = pd.to_datetime(df_flood[\"year\"], format=\"%Y\")\n",
    "\n",
    "mask = df_flood[\"year\"].dt.year >= 2009\n",
    "df_flood = df_flood.loc[mask]\n",
    "\n",
    "df_flood.sort_values(by='year', inplace=True)\n",
    "df_flood.dropna(inplace=True)\n",
    "df_flood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b076bf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144612, 9)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rainfall['date'] = pd.to_datetime(df_rainfall['date'], format='%Y-%m-%d')\n",
    "df_rainfall['year'] = df_rainfall['date'].dt.year\n",
    "df_rainfall = df_rainfall[(df_rainfall['year'] >= 2009) & (df_rainfall['year'] <= 2019)]\n",
    "df_rainfall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1d984374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Duration(Days)</th>\n",
       "      <th>State</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>951</td>\n",
       "      <td>2009-11-03</td>\n",
       "      <td>2009-11-08</td>\n",
       "      <td>5</td>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>948</td>\n",
       "      <td>/07/2009</td>\n",
       "      <td>/09/2009</td>\n",
       "      <td>Diffing the dates</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>949</td>\n",
       "      <td>2009-09-25</td>\n",
       "      <td>2009-10-12</td>\n",
       "      <td>17</td>\n",
       "      <td>KARNATAKA</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>950</td>\n",
       "      <td>2009-10-09</td>\n",
       "      <td>2009-10-09</td>\n",
       "      <td>0</td>\n",
       "      <td>MEGHALAYA</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>641</td>\n",
       "      <td>2009-03-11</td>\n",
       "      <td>2009-08-11</td>\n",
       "      <td>153</td>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>120</td>\n",
       "      <td>MAHARASHTRA</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>718</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>2019-07-13</td>\n",
       "      <td>16</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1025</td>\n",
       "      <td>2019-10-19</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>4</td>\n",
       "      <td>KARNATAKA</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>725</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>Diffing the dates</td>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1026</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>5</td>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Start Date    End Date     Duration(Days)        State  \\\n",
       "951          951  2009-11-03  2009-11-08                  5   TAMIL NADU   \n",
       "948          948    /07/2009    /09/2009  Diffing the dates        ASSAM   \n",
       "949          949  2009-09-25  2009-10-12                 17    KARNATAKA   \n",
       "950          950  2009-10-09  2009-10-09                  0    MEGHALAYA   \n",
       "641          641  2009-03-11  2009-08-11                153   TAMIL NADU   \n",
       "...          ...         ...         ...                ...          ...   \n",
       "719          719  2019-01-07  2019-05-07                120  MAHARASHTRA   \n",
       "718          718  2019-06-27  2019-07-13                 16        ASSAM   \n",
       "1025        1025  2019-10-19  2019-10-23                  4    KARNATAKA   \n",
       "725          725  2019-11-30  2019-06-12  Diffing the dates   TAMIL NADU   \n",
       "1026        1026  2019-11-29  2019-12-04                  5   TAMIL NADU   \n",
       "\n",
       "           year  \n",
       "951  2009-01-01  \n",
       "948  2009-01-01  \n",
       "949  2009-01-01  \n",
       "950  2009-01-01  \n",
       "641  2009-01-01  \n",
       "...         ...  \n",
       "719  2019-01-01  \n",
       "718  2019-01-01  \n",
       "1025 2019-01-01  \n",
       "725  2019-01-01  \n",
       "1026 2019-01-01  \n",
       "\n",
       "[624 rows x 6 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449eebe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State       date  flood\n",
      "0  TAMIL NADU 2009-01-01      0\n",
      "1  TAMIL NADU 2009-01-02      0\n",
      "2  TAMIL NADU 2009-01-03      0\n",
      "3  TAMIL NADU 2009-01-04      0\n",
      "4  TAMIL NADU 2009-01-05      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bekim\\AppData\\Local\\Temp\\ipykernel_329440\\3731402596.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_flood['Start Date'] = df_flood['Start Date'].clip(lower=start_all, upper=end_all)\n",
      "C:\\Users\\bekim\\AppData\\Local\\Temp\\ipykernel_329440\\3731402596.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_flood['End Date']   = df_flood['End Date'].clip(lower=start_all, upper=end_all)\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and transformation steps\n",
    "\n",
    "# 1) Parse dates; coerce bad strings (e.g., \"Diffing the dates\") to NaT\n",
    "for col in ['Start Date', 'End Date']:\n",
    "    df_flood[col] = pd.to_datetime(df_flood[col], errors='coerce')\n",
    "\n",
    "# 2) Duration numeric (for repairing missing/invalid End Date)\n",
    "df_flood['Duration(Days)'] = pd.to_numeric(df_flood['Duration(Days)'], errors='coerce')\n",
    "\n",
    "# 3) If End Date is missing but we have Start Date + Duration, compute End = Start + (Duration-1) days\n",
    "mask_fix = df_flood['End Date'].isna() & df_flood['Start Date'].notna() & df_flood['Duration(Days)'].notna()\n",
    "df_flood.loc[mask_fix, 'End Date'] = df_flood.loc[mask_fix, 'Start Date'] + pd.to_timedelta(df_flood.loc[mask_fix, 'Duration(Days)'] - 1, unit='D')\n",
    "\n",
    "# 4) Drop rows still missing critical fields\n",
    "df_flood = df_flood.dropna(subset=['Start Date', 'End Date', 'State'])\n",
    "\n",
    "# 5) If End < Start (e.g., data entry error), swap them\n",
    "swap = df_flood['End Date'] < df_flood['Start Date']\n",
    "df_flood.loc[swap, ['Start Date','End Date']] = df_flood.loc[swap, ['End Date','Start Date']].values\n",
    "\n",
    "# 6) Clamp to the analysis window\n",
    "start_all = pd.Timestamp('2009-01-01')\n",
    "end_all   = pd.Timestamp('2019-12-31')\n",
    "df_flood['Start Date'] = df_flood['Start Date'].clip(lower=start_all, upper=end_all)\n",
    "df_flood['End Date']   = df_flood['End Date'].clip(lower=start_all, upper=end_all)\n",
    "\n",
    "# 7) Build per-row date ranges and explode to daily rows for flooding periods\n",
    "ranges = (df_flood\n",
    "    .assign(date=df_flood.apply(lambda r: pd.date_range(r['Start Date'], r['End Date']), axis=1))\n",
    "    .explode('date')[['State','date']]\n",
    "    .drop_duplicates()\n",
    "    .assign(flood=1)\n",
    ")\n",
    "\n",
    "# 8) Create full State × Date grid (all days, all states)\n",
    "states = df_flood['State'].dropna().unique()\n",
    "all_dates = pd.date_range(start_all, end_all, freq='D')\n",
    "full = pd.MultiIndex.from_product([states, all_dates], names=['State','date']).to_frame(index=False)\n",
    "\n",
    "# 9) Left-join flooding days onto the full grid; fill others with 0\n",
    "out = full.merge(ranges, on=['State','date'], how='left')\n",
    "out['flood'] = out['flood'].fillna(0).astype('int8')\n",
    "\n",
    "# columns ['State','date','flood']\n",
    "\n",
    "panel = out.pivot(index='date', columns='State', values='flood').fillna(0).astype('int8')\n",
    "days_by_state = out.groupby('State')['flood'].sum()\n",
    "\n",
    "print(out.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4562d009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>date</th>\n",
       "      <th>flood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>2009-03-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>2009-03-12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>2009-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>2009-03-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>2009-03-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122969</th>\n",
       "      <td>CHATTISGARH</td>\n",
       "      <td>2015-09-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122970</th>\n",
       "      <td>CHATTISGARH</td>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122971</th>\n",
       "      <td>CHATTISGARH</td>\n",
       "      <td>2015-09-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122972</th>\n",
       "      <td>CHATTISGARH</td>\n",
       "      <td>2015-09-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122973</th>\n",
       "      <td>CHATTISGARH</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15131 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              State       date  flood\n",
       "69       TAMIL NADU 2009-03-11      1\n",
       "70       TAMIL NADU 2009-03-12      1\n",
       "71       TAMIL NADU 2009-03-13      1\n",
       "72       TAMIL NADU 2009-03-14      1\n",
       "73       TAMIL NADU 2009-03-15      1\n",
       "...             ...        ...    ...\n",
       "122969  CHATTISGARH 2015-09-26      1\n",
       "122970  CHATTISGARH 2015-09-27      1\n",
       "122971  CHATTISGARH 2015-09-28      1\n",
       "122972  CHATTISGARH 2015-09-29      1\n",
       "122973  CHATTISGARH 2015-09-30      1\n",
       "\n",
       "[15131 rows x 3 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flood_2 = out.copy()\n",
    "\n",
    "df_flood_2[df_flood_2['flood'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d1d273ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ANDAMAN & NICOBAR ISLANDS', 'ANDHRA  PRADESH', 'ANDHRA PRADESH',\n",
       "       'ARUNACHAL PRADESH', 'ASSAM', 'BIHAR', 'CHATTISGARH',\n",
       "       'CHHATTISGARH', 'GUJARAT', 'HIMACHAL PRADESH', 'JAMMU & KASHMIR',\n",
       "       'JHARKHAND', 'KARNATAKA', 'KERALA', 'MADHYA PRADESH',\n",
       "       'MAHARASHTRA', 'MEGHALAYA', 'MIZORAM', 'NAGALAND', 'NEW DELHI',\n",
       "       'ODISHA', 'PUDUCHERRY', 'PUNJAB', 'RAJASTHAN', 'SIKKIM',\n",
       "       'TAMIL NADU', 'TELANGANA', 'TRIPURA', 'UTTAR PRADESH',\n",
       "       'UTTARAKHAND', 'WEST BENGAL'], dtype=object)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = df_flood_2['State'].dropna().unique()\n",
    "states.sort()\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "72e1f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_state(name):\n",
    "    for state in states:\n",
    "        if state.lower().strip() in str(name).lower().strip():\n",
    "            return state\n",
    "    return np.nan\n",
    "\n",
    "df_rainfall['state_clean'] = df_rainfall['state_name'].apply(check_state)\n",
    "\n",
    "df_rainfall_2 = df_rainfall.dropna(subset=[\"state_clean\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9c3ee6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UTTARAKHAND', 'ASSAM', 'TRIPURA', 'TELANGANA', 'HIMACHAL PRADESH',\n",
       "       'MEGHALAYA', 'MAHARASHTRA', 'PUNJAB', 'JHARKHAND',\n",
       "       'ANDHRA PRADESH', 'ARUNACHAL PRADESH', 'UTTAR PRADESH',\n",
       "       'MADHYA PRADESH', 'KARNATAKA', 'WEST BENGAL', 'RAJASTHAN',\n",
       "       'CHHATTISGARH', 'NAGALAND', 'BIHAR', 'PUDUCHERRY', 'GUJARAT',\n",
       "       'ODISHA', 'TAMIL NADU', 'KERALA', 'SIKKIM', 'MIZORAM'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rainfall_2['state_name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "977529d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rainfall_2.drop(columns=['state_name', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7213e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = df_rainfall_2.merge(df_flood_2, left_on=['state_clean', 'date'], right_on=['State', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3c1c6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.to_csv('../data/merged_flood_rainfall.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flood_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
